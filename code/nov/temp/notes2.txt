LPAD stories are often larger and more complex, and in most cases, they end up being completed by the dev team only in the last 2 days of the sprint. This puts pressure on the team and results in QA receiving the items at the very last minute.

We’d like to move towards a better story breakdown — similar to how the LANO team structures their work. Their approach allows for smaller, manageable pieces to be delivered to QA earlier in the sprint, rather than pushing a bulk of the work at the end.

Adopting a similar model will help improve our delivery flow, reduce last-minute pressure, and give QA sufficient time for thorough testing.



We didn’t have a formal R2 release walkthrough, but having one would have been extremely valuable for the entire Agile team.

A proper walkthrough would have helped us in the following ways:
Provided a clear understanding of the overall scope, business objectives, and expected outcomes
Defined the target release timeline, intermediate milestones, and critical dates
Identified all epics, pods involved, and highlighted cross-functional dependencies
End-to-end business validation, regression scope
Improved our ability to plan sprints realistically with the right backlog prioritization
Surfaced potential risks or blockers early, allowing us to mitigate before sprint execution
Reduced confusion during the sprint by setting clear business and technical alignment
Would have served as a single point of reference throughout the release cycle
Allowed us to identify any gaps in infrastructure or environments in advance
Overall, it would have created better visibility, confidence, and collaboration across teams and reduced the usual last-minute pressure.


Each pod should receive a clear scope walkthrough specific to their items for Release R2.
This ensures that every team fully understands their responsibilities, deliverables, and timelines for the release.

However, we observed some challenges in the overall release coordination:
The overall scope was assumed as one big number, without a clear view of how it's broken down per pod.
There was a tendency to estimate timelines based on T-shirt sizing, which didn’t always reflect the actual effort or complexity.
This led to misaligned expectations, last-minute escalations, and inefficiencies in tracking progress toward the release target.
As a result, pressure or follow-up was sometimes directed at the wrong pod, while the actual delay may have been with a different team.


It would be helpful to track progress at the pod level against their defined scope, and surface delays or blockers more transparently. This way, the right support and attention can be given to the pods that need it, and we can better align on realistic timelines and dependencies.  
importantly it will really avoid putting pressure to wrong pod instead of focus on slow running pod.
